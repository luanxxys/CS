{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module and train/test set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Control warning error output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# combine the train set and predict set to simplify the step\n",
    "# 处理缺失数据等步骤, 统一进行处理令操作简洁\n",
    "full=pd.concat([train,test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket  \n",
       "0       3    male      1       0.0         A/5 21171  \n",
       "1       1  female      1       1.0          PC 17599  \n",
       "2       3  female      0       1.0  STON/O2. 3101282  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据集样本示例\n",
    "full.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      "Age            1046 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# 统计所给数据信息，包括每个属性的类型（字符，布尔或者是数值类型），以及每个属性是否缺失数据\n",
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看数据集统计信息\n",
    "# full.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值插补\n",
    "\n",
    "观察到数据集中样本的某些特征值缺失, 如果后续选用这些特征的话, 需将其补全."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### 补全 Age 信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing 'Age' according to their 'Title'\n",
    "full['Title']=full['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "nn={'Capt':'Rareman', 'Col':'Rareman','Don':'Rareman','Dona':'Rarewoman',\n",
    "    'Dr':'Rareman','Jonkheer':'Rareman','Lady':'Rarewoman','Major':'Rareman',\n",
    "    'Master':'Master','Miss':'Miss','Mlle':'Rarewoman','Mme':'Rarewoman',\n",
    "    'Mr':'Mr','Mrs':'Mrs','Ms':'Rarewoman','Rev':'Mr','Sir':'Rareman',\n",
    "    'the Countess':'Rarewoman'}\n",
    "\n",
    "full.Title=full.Title.map(nn)\n",
    "\n",
    "# assign the female 'Dr' to 'Rarewoman'\n",
    "full.loc[full.PassengerId==797,'Title']='Rarewoman'\n",
    "full.Age.fillna(999,inplace=True)\n",
    "def girl(aa):\n",
    "    if (aa.Age!=999)&(aa.Title=='Miss')&(aa.Age<=14):\n",
    "        return 'Girl'\n",
    "    elif (aa.Age==999)&(aa.Title=='Miss')&(aa.Parch!=0):\n",
    "        return 'Girl'\n",
    "    else:\n",
    "        return aa.Title\n",
    "\n",
    "full['Title']=full.apply(girl,axis=1)\n",
    "\n",
    "Tit=['Mr','Miss','Mrs','Master','Girl','Rareman','Rarewoman']\n",
    "for i in Tit:\n",
    "    full.loc[(full.Age==999)&(full.Title==i),'Age']=full.loc[full.Title==i,'Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均值填充缺失的 Age\n",
    "# full['Age'] = full['Age'].fillna(titanic['Age'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准化（Standardization）\n",
    "\n",
    "数据的标准化是将数据按比例缩放，使之落入一个小的特定区间.\n",
    "\n",
    "各属性值之间 scale 差距太大，会影响收敛速度, 甚至不收敛.\n",
    "\n",
    "因此，需要对连续型属性归一化，让它们在[-1，1]之间.\n",
    "\n",
    "区别于 **归一化（Normalization)**\n",
    "\n",
    "- 把数据变为（0，1）之间的小数\n",
    "- 把有量纲表达式变换为无量纲表达式，成为纯量\n",
    "\n",
    "> 归一化是为了消除不同数据之间的量纲，方便数据比较和共同处理，比如在神经网络中，归一化可以加快训练网络的收敛性."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### 标准化 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "age_scale_param = scaler.fit(full['Age'].values.reshape(-1, 1))\n",
    "full['Age'] = age_scale_param.transform(full['Age'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把 字符型特征 转换成 数值型 的, 便于算法进行处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逐个将需要转化的特征进行数值化处理:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集中 Sex 的类别\n",
    "print(full['Sex'].unique())\n",
    "\n",
    "# replace all the occurences of male with the number 0\n",
    "full.loc[full['Sex']=='male', 'Sex'] = 0\n",
    "full.loc[full['Sex']=='female', 'Sex'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统一数值化处理:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical variables to numerical variables\n",
    "# predictors=['Pclass', 'Sex', 'Age']\n",
    "# full_dummies=pd.get_dummies(full[predictors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select features to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征组合\n",
    "\n",
    "Pandas 提供的功能特性可直接将不同特征组合在一起."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a familysize column\n",
    "# full['family_size'] = full['SibSp'] + full['Parch']\n",
    "\n",
    "# the .apply method generates a new series\n",
    "# full['name_length'] = full['Name'].apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到重要特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "控制变量 + 加噪声, 得分前后对比, 从而找出重要的特征."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the selected features together makes steps fewer\n",
    "predictors=['Pclass', 'Sex', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120f39bf748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "train_new = full[:891]\n",
    "\n",
    "# perform feature selection\n",
    "# k：选择的特征的个数\n",
    "selector = SelectKBest(f_classif, k=3)\n",
    "selector.fit(train_new[predictors], train_new['Survived'])\n",
    "\n",
    "# get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# plot the scores\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the important features\n",
    "predictors=['Pclass', 'Sex', 'Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### 数值类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Survived'][:890].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### 划分 训练集 与 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the processed set into train_set, train_target, predict_set\n",
    "X=full[predictors][:891]\n",
    "y=full.Survived[:891]\n",
    "test_X=full[predictors][891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model -0.7889 -0.7946\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C= 0.1)\n",
    "\n",
    "# Random Forest model -0.7957 -0.8115\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=3, n_estimators=500)\n",
    "\n",
    "# SVM model - 0.7946 -0.8136\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "svc = SVC(C=0.88, gamma=0.8, probability=True)\n",
    "\n",
    "# KNN model -0.8081 -worse\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# decision tree -0.8081 -worse\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=3)\n",
    "\n",
    "# GradientBoosting model -0.8047 -0.8081\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb =GradientBoostingClassifier(random_state=3, learning_rate=0.003, max_depth=20, n_estimators=500)\n",
    "\n",
    "# XgBoost model -0.8069 -0.8249\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(n_estimators=500,max_depth=6,learning_rate=0.03)\n",
    "\n",
    "# adaboost -0.7845 -0.7900\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(random_state=3,n_estimators=500,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过网格搜索确定最佳效果参数\n",
    "\n",
    "GridSearchCV 用于系统地遍历多种参数组合, 自动调参，只要把参数输进去，就能给出最优化的结果和参数.\n",
    "\n",
    "但是这个方法适合于小数据集，一旦数据的量级上去了，很难得出结果.\n",
    "\n",
    "数据量比较大的时候可以使用一个快速调优的方法 —— 坐标下降."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators':range(10,71,10)}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=-1,cv=5,verbose=1)\n",
    "grid_search.fit(X,y)\n",
    "grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LR', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('RF', RandomF...hm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.01, n_estimators=500, random_state=3))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft',\n",
       "         weights=[1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use VotingClassifier to ensemble the previous training classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf_soft = VotingClassifier(estimators=[('LR',lr),('RF',rf),('GDBT',gb),('SVM',svc),('KNN',knn),('D_Tree',dt),('ADAB',ada)],voting='soft')\n",
    "\n",
    "# add weights\n",
    "eclfW_soft = VotingClassifier(estimators=[('LR',lr),('RF',rf),('GDBT',gb),('SVM',svc),('KNN',knn),('D_Tree',dt),('ADAB',ada)],voting='soft',weights=[1,1,1,1,1,1,1])\n",
    "\n",
    "eclfW_soft.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "# 用 sklearn 的 learning_curve 得到 training_score 和 cv_score，使用 matplotlib 画出 learning curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=4,\n",
    "                        train_sizes=np.linspace(.05, 1., 20), verbose=0, plot=True):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.title(title)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.xlabel(\"number of train set samples\")\n",
    "        plt.ylabel(\"score\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std,\n",
    "                         alpha=0.1, color=\"b\")\n",
    "        plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std,\n",
    "                         alpha=0.1, color=\"r\")\n",
    "        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\", label=\"score of train set\")\n",
    "        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\", label=\"score of CV\")\n",
    "\n",
    "        plt.legend(loc=\"best\")\n",
    "\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "    midpoint = ((train_scores_mean[-1] + train_scores_std[-1]) + (test_scores_mean[-1] - test_scores_std[-1])) / 2\n",
    "    diff = (train_scores_mean[-1] + train_scores_std[-1]) - (test_scores_mean[-1] - test_scores_std[-1])\n",
    "    return midpoint, diff\n",
    "\n",
    "plot_learning_curve(eclfW_soft, \"learning curve\", X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "scores = cross_validation.cross_val_score(eclfW_soft, X, y, cv=5, verbose=1)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the final model to predict the given test set file,\n",
    "# make the specific format of the data stored in csv\n",
    "prediction = eclfW_soft.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'PassengerId': test['PassengerId'].as_matrix(), 'Survived': prediction.astype(np.int32)})\n",
    "result.to_csv(\"./ensemble_result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
