{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 CNN 识别 MNIST\n",
    "\n",
    "CNN 结构\n",
    "\n",
    "    卷积层 1 + 池化层 1 + 卷积层 2 + 池化层 2 + 全连接 1 + Dropout 层 + 输出层\n",
    "    \n",
    "- 卷积层\n",
    "\n",
    "        对图片的矩阵进行卷积运算，得到一些数值，作为图片的某些特征\n",
    "\n",
    "        对图像卷积，就是求卷积核作用在图像后，得到的图像对于该卷积核的累加数值。这些累加的数值可以代表这个图片的一些特征\n",
    "\n",
    "- 池化层\n",
    "\n",
    "        对上层的数据进行采样，也就是只留下一部分，这样的作用是可以缩小数据量和模糊特征\n",
    "\n",
    "- 全连接层\n",
    "\n",
    "        全连接层就是连在最后的分类器。前面卷积层和池化层进行处理后，得到了很多的特征，全连接层使用这些特征进行分类。比如识别数字，那就是对 0~9 的十个类别进行分类\n",
    "\n",
    "- Dropout 层\n",
    "\n",
    "        Dropout 层是为了防止 CNN 对训练样本过拟合，而导致处理新样本的时候效果不好，采取的丢弃部分激活参数的处理方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-b0816f401df8>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "step 0, training accuracy 0.06\n",
      "step 100, training accuracy 0.82\n",
      "step 200, training accuracy 0.94\n",
      "step 300, training accuracy 0.96\n",
      "step 400, training accuracy 1\n",
      "step 500, training accuracy 0.96\n",
      "step 600, training accuracy 0.94\n",
      "step 700, training accuracy 0.96\n",
      "step 800, training accuracy 0.92\n",
      "step 900, training accuracy 1\n",
      "step 1000, training accuracy 0.92\n",
      "step 1100, training accuracy 0.98\n",
      "step 1200, training accuracy 0.98\n",
      "step 1300, training accuracy 0.96\n",
      "step 1400, training accuracy 0.98\n",
      "step 1500, training accuracy 0.98\n",
      "step 1600, training accuracy 0.94\n",
      "step 1700, training accuracy 0.96\n",
      "step 1800, training accuracy 1\n",
      "step 1900, training accuracy 0.94\n",
      "test accuracy 0.9758\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 加载数据集\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# 以交互式方式启动 session\n",
    "# 如果不使用交互式 session，则在启动 session 前必须构建整个计算图，才能启动该计算图\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\"\"\"构建计算图\"\"\"\n",
    "# 通过占位符来为输入图像和目标输出类别创建节点\n",
    "# shape参数是可选的，有了它tensorflow可以自动捕获维度不一致导致的错误\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])  # 原始输入\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])  # 目标值\n",
    "\n",
    "# 为了不在建立模型的时候反复做初始化操作，我们定义两个函数用于初始化\n",
    "def weight_variable(shape):\n",
    "    # 截尾正态分布,stddev是正态分布的标准偏差\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 卷积核池化,步长为 1,0 边距\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\"\"\"第一层卷积\"\"\"\n",
    "# 由一个卷积和一个最大池化组成。滤波器5x5中算出32个特征，是因为使用32个滤波器进行卷积\n",
    "# 卷积的权重张量形状是[5, 5, 1, 32],1是输入通道的个数，32是输出通道个数\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "\n",
    "# 每一个输出通道都有一个偏置量\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# 为了使用卷积，必须将输入转换成4维向量，2、3维表示图片的宽、高\n",
    "# 最后一维表示图片的颜色通道（因为是灰度图像所以通道数维1，RGB图像通道数为3）\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# 第一层的卷积结果,使用Relu作为激活函数\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1))\n",
    "# 第一层卷积后的池化结果\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\"\"\"第二层卷积\"\"\"\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\"\"\"全连接层\"\"\"\n",
    "# 图片尺寸减小到7*7，加入一个有1024个神经元的全连接层\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "# 将最后的池化层输出张量reshape成一维向量\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "# 全连接层的输出\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\"\"\"使用Dropout减少过拟合\"\"\"\n",
    "# 使用placeholder占位符来表示神经元的输出在dropout中保持不变的概率\n",
    "# 在训练的过程中启用dropout，在测试过程中关闭dropout\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\"\"\"输出层\"\"\"\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "# 模型预测输出\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# 交叉熵损失\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "\n",
    "# 模型训练,使用AdamOptimizer来做梯度最速下降\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# 正确预测,得到True或False的List\n",
    "correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y_conv, 1))\n",
    "# 将布尔值转化成浮点数，取平均值作为精确度\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# 在session中先初始化变量才能在session中调用\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 迭代优化模型\n",
    "for i in range(2000):\n",
    "    # 每次取50个样本进行训练\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch[0], y_: batch[1], keep_prob: 1.0})  # 模型中间不使用dropout\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x:batch[0], y_:batch[1], keep_prob: 0.5})\n",
    "print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n",
    "            x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[reference](https://www.waitig.com/python-tensorflow-%E5%9F%BA%E4%BA%8Ecnn%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
